{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000L, 100L)\n",
      "7.11318985047e-07\n",
      "0.999998022313\n",
      "(100L, 1L)\n",
      "(10000L, 1L)\n"
     ]
    }
   ],
   "source": [
    "n=10000\n",
    "p=100\n",
    "# X is a nXp matrix\n",
    "X=np.random.rand(n,p)\n",
    "print X.shape\n",
    "print np.amin(X) \n",
    "print np.amax(X) \n",
    "# True Beta is 1\n",
    "BStar = np.ones((p,1), dtype=np.float)\n",
    "BInit = np.full((p, 1), 0.7)\n",
    "print BStar.shape\n",
    "# Noise scaled to be between 0 and 0.1\n",
    "w = np.random.rand(n,1) * 0.1\n",
    "# Compute y with noise\n",
    "y = np.dot(X,BStar) + w\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def B_grad(x, B, y, n):\n",
    "    sum = 0.0\n",
    "    # have to iterate through all n data points to compute full gradient\n",
    "    for i in np.arange(n):\n",
    "        sum = sum + 2 * x[i,:] * (np.dot(x[i,:],B) - y[i]) \n",
    "    return sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time  10.6190001965\n"
     ]
    }
   ],
   "source": [
    "# Answer to part C - Gradient Descent\n",
    "beta_step = np.full((p, 1), 0.7)\n",
    "\n",
    "iterations = 100\n",
    "eta = 0.022\n",
    "time_step = np.array([0.])\n",
    "start_time = time.time()\n",
    "for i in np.arange(iterations)+1:\n",
    "    beta_next = beta_step[:,-1] - eta *B_grad(X,beta_step[:,-1], y, n)\n",
    "    beta_step = np.c_[beta_step,beta_next]\n",
    "    time_step = np.concatenate((time_step,np.array([time.time() - start_time])))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print \"Elapsed Time \",elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7       ,  1.03374503,  0.99899654,  1.00260485,  1.0022206 ,\n",
       "        1.00225198,  1.00224012,  1.0022328 ,  1.00222503,  1.00221735,\n",
       "        1.00220968,  1.00220205,  1.00219444,  1.00218686,  1.0021793 ,\n",
       "        1.00217178,  1.00216428,  1.00215681,  1.00214936,  1.00214195,\n",
       "        1.00213456,  1.00212719,  1.00211986,  1.00211255,  1.00210527,\n",
       "        1.00209801,  1.00209078,  1.00208358,  1.0020764 ,  1.00206925,\n",
       "        1.00206213,  1.00205503,  1.00204796,  1.00204091,  1.00203389,\n",
       "        1.00202689,  1.00201992,  1.00201298,  1.00200606,  1.00199916,\n",
       "        1.00199229,  1.00198545,  1.00197863,  1.00197184,  1.00196507,\n",
       "        1.00195832,  1.0019516 ,  1.00194491,  1.00193824,  1.00193159,\n",
       "        1.00192497,  1.00191837,  1.00191179,  1.00190524,  1.00189872,\n",
       "        1.00189221,  1.00188573,  1.00187928,  1.00187285,  1.00186644,\n",
       "        1.00186005,  1.00185369,  1.00184735,  1.00184104,  1.00183474,\n",
       "        1.00182847,  1.00182223,  1.001816  ,  1.0018098 ,  1.00180362,\n",
       "        1.00179747,  1.00179133,  1.00178522,  1.00177913,  1.00177307,\n",
       "        1.00176702,  1.001761  ,  1.001755  ,  1.00174902,  1.00174306,\n",
       "        1.00173713,  1.00173121,  1.00172532,  1.00171945,  1.0017136 ,\n",
       "        1.00170777,  1.00170196,  1.00169618,  1.00169041,  1.00168467,\n",
       "        1.00167895,  1.00167325,  1.00166756,  1.0016619 ,  1.00165626,\n",
       "        1.00165065,  1.00164505,  1.00163947,  1.00163391,  1.00162837,\n",
       "        1.00162286])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_step[5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9851796348745497e-06"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute StepSize\n",
    "1/np.amax(np.linalg.eig(np.dot(X.T,X))[0])\n",
    "#X.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
